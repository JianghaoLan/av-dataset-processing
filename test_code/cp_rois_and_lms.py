import argparse
import os
import shutil
import concurrent.futures
from utils.media_utils import get_media_duration, get_video_fps, get_video_frame_count, trim_audio, trim_video


class SyncMeta:
    def __init__(self, id, vid, result_desp, best_offset, best_score, num_samples):  
        self.id = id
        self.vid = vid
        self.result_desp = result_desp
        self.best_offset = best_offset
        self.best_score = best_score
        self.num_samples = num_samples


def gen_sync_result(sync_result_list_path):
    with open(sync_result_list_path) as f:
        lines = f.readlines()
    for line in lines:
        data_path, result_desp, best_offset, best_score, num_samples = line.strip().split()
        id, vid = data_path.split('/')
        best_offset = int(best_offset)
        best_score = float(best_score)
        num_samples = int(num_samples)
        assert result_desp in ['no_enough_samples', 'low_score', 'success']
        yield SyncMeta(id, vid, result_desp, best_offset, best_score, num_samples)


def float_equal(value, other, eps=1e-9):
    return abs(value - other) < eps
    
        
def cp(sync_result_list_path, src_dataset_root, dst_dataset_root, dry_run=False):
    datas = list(gen_sync_result(sync_result_list_path))
    ids = set(map(lambda data: data.id, datas))
    print('Sync result list path:', sync_result_list_path)
    print('Total synced video num:', len(datas))
    print('Total id num:', len(ids))
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=32) as executor:
        def map_already_sync_datas(_data: SyncMeta):
            if _data.result_desp != 'success' or _data.best_offset != 0:
                return _data, False
            video_dur = get_media_duration(os.path.join(src_dataset_root, _data.id, _data.vid, 'video.mp4'))
            ori_video_dur = get_media_duration(os.path.join(src_dataset_root, _data.id, _data.vid, 'ori_video.mp4'))
            audio_dur = get_media_duration(os.path.join(src_dataset_root, _data.id, _data.vid, 'audio.wav'))
            assert float_equal(video_dur, ori_video_dur)
            return _data, float_equal(video_dur, audio_dur)
        already_sync_datas = list(map(lambda x: x[0], filter(lambda x: x[1], executor.map(map_already_sync_datas, datas))))
    # already_sync_datas = list(filter(is_already_sync_datas, datas))
    already_sync_ids = set(map(lambda data: data.id, already_sync_datas))
    print('Total already sync video num:', len(already_sync_datas))
    print('Total already sync id num:', len(already_sync_ids))
    for i, data in enumerate(already_sync_datas, 1):
        id = data.id
        vid = data.vid
        src_dir = os.path.join(src_dataset_root, id, vid)
        dst_dir = os.path.join(dst_dataset_root, id, vid)
        src_ori_video = os.path.join(src_dir, 'ori_video.mp4')
        src_rois = os.path.join(src_dir, 'rois.json')
        src_lms = os.path.join(src_dir, 'landmarks.json')
        dst_ori_video = os.path.join(dst_dir, 'ori_video.mp4')
        dst_rois = os.path.join(dst_dir, 'rois.json')
        dst_lms = os.path.join(dst_dir, 'landmarks.json')
        assert not os.path.exists(dst_rois) and not os.path.exists(dst_lms) and not os.path.exists(dst_ori_video), f'dst dir: {dst_dir}'
        if not dry_run:
            shutil.copyfile(src_ori_video, dst_ori_video)
            shutil.copyfile(src_rois, dst_rois)
            shutil.copyfile(src_lms, dst_lms)
        if i % 100 == 0:
            print(f'Process {i}/{len(already_sync_datas)} completed.')
    if not dry_run:
        print('Checking all the datas...')
        for i, data in enumerate(datas, 1):
            if data.result_desp != 'success':
                continue
            id = data.id
            vid = data.vid
            dst_dir = os.path.join(dst_dataset_root, id, vid)
            assert os.path.exists(os.path.join(dst_dir, 'rois.json')) and os.path.exists(os.path.join(dst_dir, 'landmarks.json')) \
                and os.path.exists(os.path.join(dst_dir, 'audio.wav')) and os.path.exists(os.path.join(dst_dir, 'video.mp4')) \
                and os.path.exists(os.path.join(dst_dir, 'ori_video.mp4')), f'dst dir: {dst_dir}'
            if i % 100 == 0:
                print(f'Check {i}/{len(datas)} completed.')


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--sync_result_list_path', type=str, required=True, help='root of result filelist generated by sync_dataset.py')
    parser.add_argument('--src_dataset_root', type=str, required=True)
    parser.add_argument('--dst_dataset_root', type=str, required=True)
    parser.add_argument('--dry_run', action='store_true', help='Dry run this script without generate output file')
    args = parser.parse_args()
    
    sync_result_list_path = args.sync_result_list_path
    src_dataset_root = args.src_dataset_root
    dst_dataset_root = args.dst_dataset_root
    dry_run = args.dry_run
    cp(sync_result_list_path, src_dataset_root, dst_dataset_root, dry_run)
    

if __name__ == '__main__':
    main()
